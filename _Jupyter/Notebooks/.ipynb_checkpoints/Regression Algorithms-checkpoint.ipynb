{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Regression Algorithms to use:\n",
    "\n",
    "\n",
    "## 1. Linear Regression\n",
    "\n",
    "It is used to estimate real values (cost of houses, number of calls, total sales etc.) based on continuous variable(s). Here, we establish relationship between independent and dependent variables by fitting a best line. This best fit line is known as regression line and represented by a linear equation Y= a *X + b.\n",
    "\n",
    "The best way to understand linear regression is to relive this experience of childhood. Let us say, you ask a child in fifth grade to arrange people in his class by increasing order of weight, without asking them their weights! What do you think the child will do? He / she would likely look (visually analyze) at the height and build of people and arrange them using a combination of these visible parameters. This is linear regression in real life! The child has actually figured out that height and build would be correlated to the weight by a relationship, which looks like the equation above.\n",
    "\n",
    "In this equation:\n",
    "\n",
    "Y – Dependent Variable\n",
    "a – Slope\n",
    "X – Independent variable\n",
    "b – Intercept\n",
    "These coefficients a and b are derived based on minimizing the sum of squared difference of distance between data points and regression line.\n",
    "\n",
    "Look at the below example. Here we have identified the best fit line having linear equation y=0.2811x+13.9. Now using this equation, we can find the weight, knowing the height of a person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is of mainly two types: Simple Linear Regression and Multiple Linear Regression. Simple Linear Regression is characterized by one independent variable. And, Multiple Linear Regression(as the name suggests) is characterized by multiple (more than 1) independent variables. While finding best fit line, you can fit a polynomial or curvilinear regression. And these are known as polynomial or curvilinear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "#Import other necessary libraries like pandas, numpy...\n",
    "from sklearn import linear_model\n",
    "#Load Train and Test datasets\n",
    "#Identify feature and response variable(s) and values must be numeric and numpy arrays\n",
    "x_train=input_variables_values_training_datasets\n",
    "y_train=target_variables_values_training_datasets\n",
    "x_test=input_variables_values_test_datasets\n",
    "# Create linear regression object\n",
    "linear = linear_model.LinearRegression()\n",
    "# Train the model using the training sets and check score\n",
    "linear.fit(x_train, y_train)\n",
    "linear.score(x_train, y_train)\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', linear.coef_)\n",
    "print('Intercept: \\n', linear.intercept_)\n",
    "#Predict Output\n",
    "predicted= linear.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.kNN (K-Nearest Neighbors)\n",
    "\n",
    "It can be used for both classification and regression problems. However, it is more widely used in classification problems in the industry. K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\n",
    "\n",
    "These distance functions can be Euclidean, Manhattan, Minkowski and Hamming distance. First three functions are used for continuous function and fourth one (Hamming) for categorical variables. If K = 1, then the case is simply assigned to the class of its nearest neighbor. At times, choosing K turns out to be a challenge while performing kNN modeling.\n",
    "\n",
    "KNN can easily be mapped to our real lives. If you want to learn about a person, of whom you have no information, you might like to find out about his close friends and the circles he moves in and gain access to his/her information!\n",
    "\n",
    "Things to consider before selecting kNN:\n",
    "\n",
    "* KNN is computationally expensive\n",
    "* Variables should be normalized else higher range variables can bias it\n",
    "* Works on pre-processing stage more before going for kNN like outlier, noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create KNeighbors classifier object model \n",
    "KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
